---
tags:
  - "#sketch"
link-tags: 
aliases:
  - resumo livro Introduction to stochastic process
---
## 3 Cadeias de Markov a longo tempo
### 3.1 Distribuição no limite
**Definições**: (Distribuição no Limite)
![[Pasted image 20240819095536.png]]
![[Pasted image 20240819095616.png]]
![[Pasted image 20240819095641.png]]

Pela unicidade de limites, se uma cadeia de Markov tem distribuição no limite, então essa distribuição é única.
#### Proporção do tempo em cada estado
A proporção do tempo em um determinado estado é dada pela distribuição no limite desse estado.

### 3.2 Distribuição estacionária
**Definição**: (Distribuição Estacionária)
![[Pasted image 20240819100120.png]]

#### Distribuições no limite são distribuições estacionárias
**Lema**: (Distribuições no Limite são Distribuições Estacionárias)
![[Pasted image 20240819100400.png]]

Repare que a volta **não** é verdadeira. Ou seja, não é verdade, necessariamente, que se $\pi$ é uma distribuição estacionária, então $\pi$ é a distribuição no limite.

Existem cadeia de Markov com mais de uma distribuição estacionária; existem cadeias de Markov com distribuições estacionárias únicas que não é a distribuição no limite; e existe cadeias de Markov que não possuem distribuição estacionárias.

#### Matriz de transição regular
**Definição**: (Matriz de Transição Regular)
![[Pasted image 20240819101142.png]]

**Teorema**: (Teorema do Limite para Cadeias de Markov Regulares)
![[Pasted image 20240819101220.png]]
![[Pasted image 20240819101559.png]]

Se, para alguma potência $n$, todos os 0s de $P^n$ aparecem nos mesmos locais de todos os 0s de $P^{n+1}$, então eles aparecerão nessa mesma localização para todas as potências maiores, e a matriz não é regular.
#### Encontrando a distribuição estacionária
Ver pág. 85 da referência.

### 3.3 Você consegue encontrar o caminho até o estado $a$?
**Definição**: (Irredutibilidade)
![[Pasted image 20240819110840.png]]

#### Recorrência e transiência
**Definição**: (Primeira Passagem por um Estado) A primeira passagem por um estado é denotada por $T_j = min\{n > 0| X_n = j\}$.

**Definição**: (Recorrência e Transiência)
![[Pasted image 20240819111159.png]]

**Lema**:
![[Pasted image 20240819111409.png]]

**Teorema**: (Recorrência e Transiência são Propriedades de Classes)
![[Pasted image 20240819111529.png]]

**Corolário**:
![[Pasted image 20240819111610.png]]

#### Decomposição canônica
**Definição**: (Conjunto de estados fechados) Dizemos que um conjunto de estados $C$ é fechado se $P_{ij} = 0 \quad \forall i \in C, j \notin C$. 

**Lema**: (Classe de Comunicação Fechada)
![[Pasted image 20240822075223.png]]

É possível particionar o espaço de estados de uma cadeia de Markov em estados transientes e recorrentes, e posteriormente, reescrever a matriz de transição. Isso pode nos ajudar a trabalhar essa matriz, pois poderemos aplicar os resultados válidos apenas cadeias irredutíveis em cadeias não irredutíveis.

### 3.4 Cadeias de Markov irredutíveis
**Definição**: (Tempo Médio de Retorno) O tempo médio de retorno a um estado é denotado por $\mu_j = E[T_j|X_0 = j]$, onde $T_j$ é o índice da primeira passagem pelo estado $j$.

**Teorema**: (Teorema do Limite para Cadeias de Markov Finitas e Irredutíveis)
![[Pasted image 20240822081057.png]]
*Notas*:
* O teorema **não** afirma que $\pi$ é uma distribuição no limite. (Ver mais sobre pág. 104)
* O teorema também vale para cadeias irredutíveis infinitas contanto que $E[T_j|X_0 = j] < \infty$. Nesse caso, dizemos que os estados da cadeia são **recorrentes positivos**; caso contrário ($E[T_j|X_0 = j] = \infty$), dizemos que a cadeia é **recorrente nula**.

#### Análise de primeiro passo
O tempo de retorno médio pode ser encontrado utilizando a probabilidade estacionária (para cadeias irredutíveis). Mas essa não é a única maneira: podemos utilizar a análise de primeira passo também.

Ver página 105

### 3.5 Periodicidade
Uma CM irredutível finita tem distribuição estacionária positiva e única (Teorema 3.6), mas isso não garante que ela tenha distribuição no limite.

**Definição**: (Período)
![[Pasted image 20240827091629.png]]

**Lema**: (Periodicidade é uma Propriedade de Classe)
![[Pasted image 20240827091717.png]]
Daqui, segue que todos os estados de uma CM irredutível têm o mesmo período.

**Definição**: (Cadeia de Markov Periódica e Aperiódica)
![[Pasted image 20240827092446.png]]
Note que se $P_{ii} > 0$, então o estado $i$ é aperiódico; segue disso que, se a CM for irredutível e houver pelo menos um elemento positivo na diagonal da matriz de transição, todos os estados serão aperiódicos.

### 3.6 Cadeias de Markov ergóticas
**Definição**: (Cadeia de Markov Ergótica) Uma CM é dita ergótica se for irredutível, aperiódica e possuir tempo médio de retorno finito. Como toda CM finita tem tempo médio de retorno finito, nesse caso, basta ela ser aperiódica e irredutível para ser ergótica.

**Teorema**: (Teorema Fundamental do Limite para Cadeias de Markov Ergóticas)
![[Pasted image 20240827094813.png]]
*Nota*: repare que o mesmo foi dito para quando a matriz de transição é regular. Não surpreendentemente, uma CM será ergótica se, e somente se, sua matriz de transição for regular.

### 3.7 Reversibilidade temporal
A ideia é que um passeio aleatório em uma dimensão será reversível se $p = 1-p = 0.5$, pois a evolução da cadeia observada de trás pra frente ($X_0, X_1, \dots , X_n$) é indistinguível em relação a olhar de frente pra trás ($X_n, X_{n-1}, \dots , X_0$), enquanto que, se $p > 0.5$, haverá uma tendência crescente dos valores que a cadeia assume com o passar do tempo. O mesmo raciocínio, agora invertido, vale para caso $p < 0.5$.

**Definição**: (Reversibilidade temporal) (Equações de balanço detalhado)
![[Pasted image 20240827104936.png]]
*Nota*: para verificar que uma CM irredutível é reversível, temos que testar se essa equação vale para todos os pares do espaço de estados.

![[Pasted image 20240911084314.png]]

### 3.8 Cadeias absorventes
**Definição**: (Cadeias de Markov absorventes)
![[Pasted image 20240911085337.png]]

![[Pasted image 20240911102008.png]]
![[Pasted image 20240911102112.png]]
*Nota*: A matriz $(I - Q)^{-1}R$  nos dá a probabilidade a longo prazo de que a cadeia, começando no estado $i$, seja absorvida pelo estado $j$.

**Definição**: (Matriz fundamental) A matriz $(I - Q)^{-1}$ é denominada matriz fundamental. Ela nos dá a quantidade esperada de visitas da cadeia ao estado $j$ dado que ela começou em $i$.

**Teorema**: (Número esperado de visitas a um estado transiente)
![[Pasted image 20240911102411.png]]

#### Tempo esperado para absorção
Seja $a_i$ o número de passos esperado até absorção dado que a cadeia começou no estado $i$. Assim $a_i$ vai ser igual a soma dos números esperado de visitas de todos os estados transientes dado que a CM começou em $i$. Ou seja, $a_i = \sum_{k \in T} F_{ik}$. Portanto, $a_i$ é a soma da linha $i$ da matriz fundamental $F$.

![[Pasted image 20240911105707.png]]

#### Tempo esperado até a primeira visita numa cadeia irredutível
Podemos calcular o tempo esperado até a primeira visita a um estado em uma CM irredutível fazendo uma transformação da sua matriz de transição. A transformação envolve em transformar o estado de interesse, $i$, em um estado absorvente, e utilizando das técnicas vistas acima, montar a matriz $Q$ removendo a linha e a coluna correspondentes ao estado $i$, para então poder calcular $F = (I - Q)^{-1}$.  Com essa matriz em mãos, podemos obter o tempo esperado para absorção partindo de cada um dos estados transientes somando-se as suas linhas. Ver pág. 129 do livro.

## 7 Cadeias de Markov em tempo contínuo
### 7.1 Introdução




# Reference
[[Introduction to stochastic processes with R]]

