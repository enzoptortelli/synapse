---
tags:
  - "#sketch"
link-tags: 
aliases:
  - Resumo inferência
---
## Capítulo 1: Teoria de Probabilidade
### 1.2 Básico da teoria de probabilidade
**Definição**: (Sigma álgebra) Uma coleção de subconjuntos do espaço amostral $S$ é chamada de *sigma algebra* (ou *algebra de Borel*), denotada por $\mathcal{B}$ se satisfaz as seguintes propriedades:
1) $\varnothing \in \mathcal{B}$.
2) Se $A \in \mathcal{B}$, então $A^c \in \mathcal{B}$ ($\mathcal{B}$ é fechado sob complementar).
3) Se $A_1, A_2, \dots \in \mathcal{B}$, então $\cup_{i = 1}^\infty A_i \in \mathcal{B}$ ($\mathcal{B}$ é fechado sob união contável).
Repare que essa definição implica que:
1) (Pelas prop. 2 e 3 + Lei de De Morgan) Se $A_1, A_2, \dots \in \mathcal{B}$, então $\cap_{i = 1}^\infty A_i \in \mathcal{B}$ ($\mathcal{B}$ é fechado sob intersecção contável).
2) (Pelas prop. 1 e 2) $S \in \mathcal{B}$.

**Definição**: (Função de probabilidade) Dado um espaço amostral $S$ e uma sigma algebra associada $\mathcal{B}$, uma função de probabilidade é uma função $P$ com domínio em $\mathcal{B}$ que satisfaz:
1) $P(A) \geq 0$ para todo $A \in \mathcal{B}$.
2) $P(S) = 1$.
3) Se $A_1, A_2, \dots$ são conjuntos disjuntos dois a dois, então $P(\cup_{i = 1}^\infty A_1) = \sum_{i = 1}^\infty P(A_i)$.

### 1.3 Probabilidade condicional e independência
**Teorema**: Se $A$ e $B$ são eventos independentes, então também serão independentes os eventos:
1) $A$ e $B^c$,
2) $A^c$ e $B$,
3) $A^c$ e $B^c$.

**Definição**: (Independência) Uma coleção de eventos $A_1, A_2, \dots$ é mutualmente independente se, para qualquer sub coleção $A_{i_1}, A_{i_2}, \dots, A_{i_k}$, temos $$ P(\cap_{j = 1}^k A_{i_j}) = \prod_{j = i}^k P(A_{i_j}).$$
### 1.4 Variáveis aleatórias
**Definição**: Uma variável aleatória é uma função do espaço amostral $S$ para os números reais.

Uma variável aleatória define um novo espaço amostral $\mathcal{X} = \{a \in \mathbb{R} | \exists \quad s \in S \quad X(s) = a\}$, $X: S \rightarrow \mathcal{X}$ . Eu imagino que esse novo espaço amostral defina uma nova sigma-álgebra, $\mathcal{B}_X$, e uma nova função de probabilidade $P_X: \mathcal{B}_X \rightarrow [0, 1]$ (fonte: vozes da minha cabeça). 

**Teorema**: A função $P_X(X = x) = P(\{s \in S | X(s) = x\})$ é uma função de probabilidade. No caso contínuo, temos $P_X(X \in A) = P(\{s \in S | X(s) \in A\})$.

### 1.5 Função de distribuição
A **toda** variável aleatória $X$, associamos uma função chamada função distribuição acumulada de $X$.

**Definição**: (Função de probabilidade acumulada) Uma função de distribuição acumulada (fda) de uma variável aleatória $X$, denotada por $F_X(x)$, é definida por $$F_X(x) = P_X(X \leq x) \quad \forall x$$
A fato de que a fda é contínua à direita vem de sua definição. Se ela fosse definida como os valores da v.a. estritamente menores que $x$ ($<$), então ela seria contínua à esquerda.

**Teorema**: Uma função $F_X$ é uma fda se, e somente se, as seguintes três condições são verdadeiras:
1) $\lim_{x \rightarrow -\infty} F(x) = 0$  e $\lim_{x \rightarrow \infty} F(x) = 1$;
2) $F_X$ é não decrescente;
3) $F_X$ é uma função contínua à direita; ou seja, $\lim_{x \rightarrow a^+} F_X(x) = F_X(a)$.

**Definição**: Uma variável aleatória será contínua se sua fda for uma função contínua, e discreta se sua fda for uma função discreta (step function).

**Definição**: Duas variáveis aleatórias, $X,Y$, são ditas identicamente distribuídas quando, para todo $A \in \mathcal{B}^1$, temos $P(X \subset A) = P(Y \subset A)$. 
Aqui, $\mathcal{B}^1$ indica a menor sigma-álgebra contendo todos os intervalos dos números reais. Mais detalhes na página 33.

**Teorema**: As seguintes afirmações são equivalentes:
1) $X$ e $Y$ são identicamente distribuídas;
2) $F_X(x) = F_Y(x)$ para todo $x$.

### 1.6 Funções densidade e massa
**Definição**: A função massa de probabilidade (fmp) de uma variável aleatória discreta é dada por $$f_X(x) = P(X = x) \quad \forall x$$

**Definição**: A função densidade de probabilidade (fdp), $f_X(x)$, de uma variável aleatória contínua $X$ é a função que satisfaz $$F_X(x) = \int_{-\infty}^x f_X(t)dt \quad \forall x$$

**Teorema**: A função $f_X(x)$ é uma fmp/fdp de uma variável aleatória $X$ se, e somente se, 
1) $f_X(x) \geq 0 \quad \forall x$;
2) $\sum_x f_X(x) = 1$ ou $\int_{-\infty}^{\infty} f_X(x)dx = 1$.

Qualquer função não negativa com integral/soma positiva finita pode ser transformada em uma fdp/fmp. Por exemplo, se $h(x)$ é qualquer função não negativa que é positiva no conjunto $A$, 0 fora dele, e $\int_{x \in A} h(x)dx = K < \infty$, então $f_X(x) = h(x)/K$ é uma fdp/fmp de uma variável aleatória $X$ que assume valores em $A$.


## Capítulo 2: Transformações e Esperanças
### 2.1 Distribuições de funções de uma variável aleatória
**Definição**: Sejam $\mathcal{X} = \{x | f_X(x) > 0 \}$ e $\mathcal{Y} = \{y | g(x) = y \quad \text{para algum} \quad x \in \mathcal{X}\}$, onde $g: \mathcal{X} \rightarrow \mathcal{Y}$ é uma função. $\mathcal{X, Y}$ são novos espaços amostrais (ver seção 1.4).

**Teorema**: Seja $X$ uma variável aleatória com função de distribuição acumulada (fda) $F_X(x)$ e seja $Y = g(X)$.  Assim,
1) Se $g$ é uma função crescente em $\mathcal{X}$, então $F_Y(y) = F_X(g^{-1}(y))$ para todo $y \in \mathcal{Y}$.
2) Se $g$ é uma função decrescente em $\mathcal{X}$ e $X$ é uma variável aleatória contínua, então $F_Y(y) = 1 - F_X(g^{-1}(y))$ para todo $y \in \mathcal{Y}$.
p.s. eu não entendi a necessidade de $X$ ser contínua para o segundo caso.
p.s.2. acho que entendi: Se $g$ é decrescente, repare que está errado escrever $$P(Y \leq y) = P(X \geq g^{-1}(y)) = \sum_{x = g^{-1}(y)}^\infty P(X = x) = 1 - \sum_{x = -\infty }^{g^{-1}(y)}P(X = x) = 1 - F_X(g^{-1}(y))$$ , pois nesse caso, $g^{-1}(y)$ está sendo contado quando tomamos o evento complementar também. Assim, para que ficasse certo, teríamos que escrever algo do tipo
$$P(Y \leq y) = P(X \geq g^{-1}(y)) = \sum_{x = g^{-1}(y)}^\infty P(X = x) = 1 - \sum_{x = -\infty }^{\lceil g^{-1}(y) - 1 \rceil}P(X = x) = 1 - F_X(\lceil g^{-1}(y) - 1 \rceil)$$

**Resultado**: (Exponencial) Se $X \sim Uniforme(0, 1)$, e $Y = - \log (X)$, então $Y \sim exp(1)$.

**Teorema**: Seja $X$ uma variável aleatória com fdp $f_X(x)$ e $Y = g(X)$, onde $g$ é uma função monótona. Suponha que $f_X$ é contínua em $\mathcal{X}$ e que $g^{-1}$ tenha derivada contínua em $\mathcal{Y}$. Então a fdp de $Y$ é dada por $$f_Y(y) = f_X(g^{-1}(y))|\frac{d}{dy} g^{-1}(y)| \mathbb{1}_{y \in \mathcal{Y}}$$

**Resultado**: (Gama inversa) Se $X \sim Gama(n, \beta)$ e $Y = \cfrac{1}{X}$, então $Y \sim InvGamma(n, \beta)$.

**Teorema**: Tenha $X$ fdp $f_X(x)$ e seja $Y = g(X)$. Suponha que existe uma partição $A_0, A_1, \dots, A_k$ de $\mathcal{X}$ tal que $P(X \in A_0) = 0$ e $f_X$ é contínua em todo $A_i$. Além disso, suponha que existem funções $g_1(x), g_2(x), \dots, g_k(x)$ definidas em $A_1, A_2, \dots, A_k$ respectivamente que satisfazem
1) $g(x) = g_i(x)$ para todo $x \in A_i$,
2) $g_i(x)$ é monótona em $A_i$,
3) o conjunto $\mathcal{Y} = \{y| y = g_i(x) \quad \text{para algum} \quad x \in A_i\}$ é o mesmo para  $i = 1, 2, \dots, k$,
4) $g^{-1}_i(y)$ tem derivada contínua em $\mathcal{Y}$, para $i = 1, 2, \dots, k$.
Então
$$f_Y(y) = \sum_{i = 1}^k f_X(g^{-1}_i(y)) |\frac{d}{dy}g^{-1}_i(y)| \mathbb{1}_{y \in \mathcal{Y}}$$
Prova em [[202410060827]].

**Teorema**: Seja $X$ uma variável contínua com $fda$ $F_X(x)$, e defina $Y = F_X(X)$. Assim, $Y \sim Uniforme(0, 1)$.

### 2.3 Momentos e função geradora de momentos
**Definição**: Para cada inteiro $n$, o $n-ésimo$ momento de $X$ ($F_X(x)$), $\mu_n'$, é definido por $$\mu_n' = E[X^n]$$. O $n-ésimo$ momento central de $X$, $\mu_n$, é definido por $$\mu_n = E[(X - \mu)^n]$$

**Definição**: Seja $X$ uma variável aleatória com $fda$ $F_X$. A função geradora de momentos de $X$, denotada por $M_X(t)$, é dada por $$M_X(t) = E[e^{tX}]$$, dado que essa esperança exista para algum $t$ na vizinhança de $0$. Ou seja, que exista $h > 0$ tal que, para todo $t \in (-h, h)$, $E[e^{tX}]$ exista; caso contrário, dizemos que a função geradora de momentos não existe.

**Observação**: Em geral, uma $fgm$ não caracteriza unicamente uma $fda$. Ou seja, pode haver duas variáveis aleatórias distintas que possuem a mesma $fgm$. Dito isso, os próximos dois teoremas nos dão condições suficientes e necessárias para que a caracterização seja única.

**Teorema**: Sejam $F_X(x)$ e $F_Y(y)$ duas $fda$ cujo todos momentos existem. Assim,
1) Se $X$ e $Y$ possuem suportes limitados, então $F_X(u) = F_Y(u)$ para todo $u$ se, e somente se, $E[X^r] = E[Y^r]$ para todo $r = 0, 1, 2, \dots$.
2) Se a função geradora de momentos existe e $M_X(t) = M_Y(t)$ para todo $t$ em alguma vizinhança de $0$, então $F_X(u) = F_Y(u)$ para todo $u$.

**Teorema**: (Convergência de $fgm$) Suponha que $\{X_1, X_2, \dots\}$ é uma sequência de variáveis aleatórias, cada uma com $fgm$ $M_{X_i}(t)$. Além disso, suponha que $$\lim_{i \rightarrow \infty} M_{X_i}(t) = M_X(t) \quad \text{para todo $t$ numa vizinhança de $0$.}$$, onde $M_X(t)$ também é uma $fgm$. Dessa forma, existe uma única $fda$ $F_X(x)$ cujo momentos são determinados por $M_X(t)$ e, para todo $x$ onde $F_X(x)$ é contínua, nós temos $$\lim_{i \rightarrow \infty} F_{X_i}(x) = F(x)$$. Isso quer dizer que convergência, para $|t| < h$, de $fgm's$ para uma $fgm$ implica convergência das $fda's$.

### 2.4 Diferenciação sob uma integral
Sinceramente, eu preciso de uma base mais sólida de cálculo para entender esse capítulo. Dito isso, a conclusão que posso ter agora é de que é necessário verificar algumas coisas antes de podermos passar uma derivada pra dentro da integral. O mesmo vale para passar uma derivada para dentro de um somatório, mas essa é bem mais simples.

### 2.6 Miscelânea
#### 2.6.1 Unicidade da sequência de momentos
Uma distribuição não é necessariamente caracterizada por seus momentos. Dito isso, existe algumas condições que são suficientes para que esse seja o caso. Aqui, o autor nos mostra três dessas condições.

#### 2.6.2 Outras funções geradoras
Além da função geradora de momentos, existem outras funções geradoras. A *função característica* é a mais útil delas, mas requer entendimento de análise complexa. As outras funções geradoras incluem a *função geradora cumulativa* e a*função geradora de momento fatorial*.

A função característica é definida por: $$\phi_X (t) = E[e^{itX}]$$, onde $i$ é o número complexo $\sqrt{(-1)}$. A função característica sempre existe e determina completamente uma distribuição. Ou seja, toda $fda$ possui uma função característica única.

**Teorema**: (Convergência de funções características) Suponha que $X_k$, $k = 1, 2, \dots$ é uma sequência de variáveis aleatórias, cada uma com função característica $\phi_{X_k}(t)$. Além disso, suponha que $$\lim_{k \rightarrow \infty} \phi_{X_k}(t) = \phi_X (t) \quad \text{para todo t numa vizinhança de 0,}$$
onde $\phi_X (t)$ é uma função característica. Então, para todo $x$ onde $F_X(x)$ é contínua, $$\lim_{k \rightarrow \infty} F_{X_k}(x) = F_X(x).$$

## 3 - Famílias de distribuições comuns
### 3.1 Introdução
Uma família de distribuição é indexada por um ou mais parâmetros, o que nos permite variar algumas características da distribuição enquanto mantemos a mesma forma funcional.

### 3.2 Distribuições discretas
**Definição**: (Distribuição discreta) Uma variável aleatória $X$ é dita ter distribuição discreta se o contra-domínio de $X$ é um conjunto contável.

##### Distribuição Uniforme Discreta
Para provar a esperança e a variância dessa distribuição, podemos usar as seguintes identidades: $$\sum_{i = 1}^n i = \cfrac{n(n+1)}{2} \quad \text{para a esperança}$$ e $$\sum_{i = 1}^n i^2 = \cfrac{n (n+1)(2n+1)}{6} \quad \text{para a variância}$$
##### Distribuição Hipergeométrica
A distribuição hipergeométrica pode ser montada da seguinte maneira: imagine que temos uma urna com $N$ bolas, das quais $M$ são vermelhas e $N - M$ são verdes. Vamos retirar dessa urna, sem reposição, $K$ bolas. Queremos saber a probabilidade de que o número de bolas vermelhas nessas $K$ bolas retiradas ser igual a $x$.

Assim, temos $\left( \begin{array}{c} N \\ K \end{array} \right)$ maneiras de retirar essa amostra. Além disso, há $\left( \begin{array}{c} M \\ x \end{array} \right)$ maneiras de que $x$ dessas bolas sejam vermelhas, e por consequência, $\left( \begin{array}{c} N - M\\ K - x\end{array} \right)$ maneiras de preencher o resto da amostra com bolas verdes. Assim, $$P(X = x | N, M, K) = \cfrac{\left( \begin{array}{c} M \\ x \end{array} \right) \left( \begin{array}{c} N - M\\ K - x\end{array} \right)}{\left( \begin{array}{c} N \\ K \end{array} \right)}$$
Lembrando que o entendimento que devemos ter aqui é de que as bolas da mesma cor são diferenciáveis entre si, como se cada uma tivesse uma marcação única.

Para encontrar a esperança da hipergeométrica, podemos usar as identidades $$x\left( \begin{array}{c} M \\ x \end{array} \right) = M\left( \begin{array}{c} M-1 \\ x-1 \end{array} \right)$$ e manipular a equação tal que tenhamos uma nova distribuição hipergeométrica com parâmetros $N-1, M-1, K-1$ somando de $0$ a $\infty$, resultando em 1.

A hipergeométrica pode ser usada em inspeção de qualidade de um lote de bens. Imagine que tenhamos $25$ produtos num lote, nós amostramos $10$ desses produtos, e nenhum deles é defeituoso. Qual a probabilidade desse evento dado que há 6 peças defeituosas no lote? Esse valor é dado por $P(X = 0 | N = 25, M = 6, K = 10) = 0.028$, demostrando que o evento é bastante improvável se há $6$ *ou mais* produtos defeituosos.

##### Distribuição Binomial
**Teorema**: (Teorema Binomial) Para quaisquer $x, y$ inteiros e $n \geq 0$, temos que $$(x + y)^n = \sum_{i = 0}^n \left( \begin{array}{c} n \\ i \end{array} \right) x^i y^{n - i}$$
A prova é a seguinte: $(x + y)^n = (x+y) (x+y) \dots (x+y)$, $n$ vezes. Pra cada um desses termos, podemos escolher $x$ ou $y$. Para $i = 0, 1, \dots, n$, temos $\left( \begin{array}{c} n \\ i \end{array} \right)$ termos em que $x$ aparece $i$ vezes, $x^i$. Isso porque, para $i = 0$, só temos uma maneira fazer a escolha: todas devem ser $y$. Para $i = 1$, temos $\left( \begin{array}{c} n \\ 1 \end{array} \right) = n$ maneiras de escolher, e assim sucessivamente.

Um corolário que segue desse teorema é a seguinte identidade: $$2^n = (1+1)^n =  \sum_{i = 0}^n \left( \begin{array}{c} n \\ i \end{array} \right)$$
Esse teorema nos ajuda a provar que a densidade da distribuição binomial avaliada em seu suporte soma 1.

##### Distribuição Poisson









# Reference
[[Statistical Inference]]

