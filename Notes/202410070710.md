---
tags:
  - "#sketch"
link-tags: 
aliases:
  - Resumo inferência
---
## Capítulo 1: Teoria de Probabilidade
### 1.2 Básico da teoria de probabilidade
**Definição**: (Sigma álgebra) Uma coleção de subconjuntos do espaço amostral $S$ é chamada de *sigma algebra* (ou *algebra de Borel*), denotada por $\mathcal{B}$ se satisfaz as seguintes propriedades:
1) $\varnothing \in \mathcal{B}$.
2) Se $A \in \mathcal{B}$, então $A^c \in \mathcal{B}$ ($\mathcal{B}$ é fechado sob complementar).
3) Se $A_1, A_2, \dots \in \mathcal{B}$, então $\cup_{i = 1}^\infty A_i \in \mathcal{B}$ ($\mathcal{B}$ é fechado sob união contável).
Repare que essa definição implica que:
1) (Pelas prop. 2 e 3 + Lei de De Morgan) Se $A_1, A_2, \dots \in \mathcal{B}$, então $\cap_{i = 1}^\infty A_i \in \mathcal{B}$ ($\mathcal{B}$ é fechado sob intersecção contável).
2) (Pelas prop. 1 e 2) $S \in \mathcal{B}$.

**Definição**: (Função de probabilidade) Dado um espaço amostral $S$ e uma sigma álgebra associada $\mathcal{B}$, uma função de probabilidade é uma função $P$ com domínio em $\mathcal{B}$ que satisfaz:
1) $P(A) \geq 0$ para todo $A \in \mathcal{B}$.
2) $P(S) = 1$.
3) Se $A_1, A_2, \dots$ são conjuntos disjuntos dois a dois, então $P(\cup_{i = 1}^\infty A_1) = \sum_{i = 1}^\infty P(A_i)$.

### 1.3 Probabilidade condicional e independência
**Teorema**: Se $A$ e $B$ são eventos independentes, então também serão independentes os eventos:
1) $A$ e $B^c$,
2) $A^c$ e $B$,
3) $A^c$ e $B^c$.

**Definição**: (Independência) Uma coleção de eventos $A_1, A_2, \dots$ é mutualmente independente se, para qualquer sub coleção $A_{i_1}, A_{i_2}, \dots, A_{i_k}$, temos $$ P(\cap_{j = 1}^k A_{i_j}) = \prod_{j = i}^k P(A_{i_j}).$$
### 1.4 Variáveis aleatórias
**Definição**: Uma variável aleatória é uma função do espaço amostral $S$ para os números reais.

Uma variável aleatória define um novo espaço amostral $\mathcal{X} = \{a \in \mathbb{R} | \exists \quad s \in S \quad X(s) = a\}$, $X: S \rightarrow \mathcal{X}$ . Eu imagino que esse novo espaço amostral defina uma nova sigma-álgebra, $\mathcal{B}_X$, e uma nova função de probabilidade $P_X: \mathcal{B}_X \rightarrow [0, 1]$ (fonte: vozes da minha cabeça). 

**Teorema**: A função $P_X(X = x) = P(\{s \in S | X(s) = x\})$ é uma função de probabilidade. No caso contínuo, temos $P_X(X \in A) = P(\{s \in S | X(s) \in A\})$.

### 1.5 Função de distribuição
A **toda** variável aleatória $X$, associamos uma função chamada função distribuição acumulada de $X$.

**Definição**: (Função de probabilidade acumulada) Uma função de distribuição acumulada (fda) de uma variável aleatória $X$, denotada por $F_X(x)$, é definida por $$F_X(x) = P_X(X \leq x) \quad \forall x$$
A fato de que a fda é contínua à direita vem de sua definição. Se ela fosse definida como os valores da v.a. estritamente menores que $x$ ($<$), então ela seria contínua à esquerda.

**Teorema**: Uma função $F_X$ é uma fda se, e somente se, as seguintes três condições são verdadeiras:
1) $\lim_{x \rightarrow -\infty} F(x) = 0$  e $\lim_{x \rightarrow \infty} F(x) = 1$;
2) $F_X$ é não decrescente;
3) $F_X$ é uma função contínua à direita; ou seja, $\lim_{x \rightarrow a^+} F_X(x) = F_X(a)$.

**Definição**: Uma variável aleatória será contínua se sua fda for uma função contínua, e discreta se sua fda for uma função discreta (step function).

**Definição**: Duas variáveis aleatórias, $X,Y$, são ditas identicamente distribuídas quando, para todo $A \in \mathcal{B}^1$, temos $P(X \subset A) = P(Y \subset A)$. 
Aqui, $\mathcal{B}^1$ indica a menor sigma-álgebra contendo todos os intervalos dos números reais. Mais detalhes na página 33.

**Teorema**: As seguintes afirmações são equivalentes:
1) $X$ e $Y$ são identicamente distribuídas;
2) $F_X(x) = F_Y(x)$ para todo $x$.

### 1.6 Funções densidade e massa
**Definição**: A função massa de probabilidade (fmp) de uma variável aleatória discreta é dada por $$f_X(x) = P(X = x) \quad \forall x$$

**Definição**: A função densidade de probabilidade (fdp), $f_X(x)$, de uma variável aleatória contínua $X$ é a função que satisfaz $$F_X(x) = \int_{-\infty}^x f_X(t)dt \quad \forall x$$

**Teorema**: A função $f_X(x)$ é uma fmp/fdp de uma variável aleatória $X$ se, e somente se, 
1) $f_X(x) \geq 0 \quad \forall x$;
2) $\sum_x f_X(x) = 1$ ou $\int_{-\infty}^{\infty} f_X(x)dx = 1$.

Qualquer função não negativa com integral/soma positiva finita pode ser transformada em uma fdp/fmp. Por exemplo, se $h(x)$ é qualquer função não negativa que é positiva no conjunto $A$, 0 fora dele, e $\int_{x \in A} h(x)dx = K < \infty$, então $f_X(x) = h(x)/K$ é uma fdp/fmp de uma variável aleatória $X$ que assume valores em $A$.


## Capítulo 2: Transformações e Esperanças
### 2.1 Distribuições de funções de uma variável aleatória
**Definição**: Sejam $\mathcal{X} = \{x | f_X(x) > 0 \}$ e $\mathcal{Y} = \{y | g(x) = y \quad \text{para algum} \quad x \in \mathcal{X}\}$, onde $g: \mathcal{X} \rightarrow \mathcal{Y}$ é uma função. $\mathcal{X, Y}$ são novos espaços amostrais (ver seção 1.4).

**Teorema**: Seja $X$ uma variável aleatória com função de distribuição acumulada (fda) $F_X(x)$ e seja $Y = g(X)$.  Assim,
1) Se $g$ é uma função crescente em $\mathcal{X}$, então $F_Y(y) = F_X(g^{-1}(y))$ para todo $y \in \mathcal{Y}$.
2) Se $g$ é uma função decrescente em $\mathcal{X}$ e $X$ é uma variável aleatória contínua, então $F_Y(y) = 1 - F_X(g^{-1}(y))$ para todo $y \in \mathcal{Y}$.
p.s. eu não entendi a necessidade de $X$ ser contínua para o segundo caso.
p.s.2. acho que entendi: Se $g$ é decrescente, repare que está errado escrever $$P(Y \leq y) = P(X \geq g^{-1}(y)) = \sum_{x = g^{-1}(y)}^\infty P(X = x) = 1 - \sum_{x = -\infty }^{g^{-1}(y)}P(X = x) = 1 - F_X(g^{-1}(y))$$ , pois nesse caso, $g^{-1}(y)$ está sendo contado quando tomamos o evento complementar também. Assim, para que ficasse certo, teríamos que escrever algo do tipo
$$P(Y \leq y) = P(X \geq g^{-1}(y)) = \sum_{x = g^{-1}(y)}^\infty P(X = x) = 1 - \sum_{x = -\infty }^{\lceil g^{-1}(y) - 1 \rceil}P(X = x) = 1 - F_X(\lceil g^{-1}(y) - 1 \rceil)$$
p.s.3. na verdade, acho que não é isso. O que o p.s.2 tem a ver com continuidade de $X$?

**Resultado**: (Exponencial) Se $X \sim Uniforme(0, 1)$, e $Y = - \log (X)$, então $Y \sim exp(1)$.

**Teorema**: Seja $X$ uma variável aleatória com fdp $f_X(x)$ e $Y = g(X)$, onde $g$ é uma função monótona. Suponha que $f_X$ é contínua em $\mathcal{X}$ e que $g^{-1}$ tenha derivada contínua em $\mathcal{Y}$. Então a fdp de $Y$ é dada por $$f_Y(y) = f_X(g^{-1}(y))|\frac{d}{dy} g^{-1}(y)| \mathbb{1}_{y \in \mathcal{Y}}$$

**Resultado**: (Gama inversa) Se $X \sim Gama(n, \beta)$ e $Y = \cfrac{1}{X}$, então $Y \sim InvGamma(n, \beta)$.

**Teorema**: Tenha $X$ fdp $f_X(x)$ e seja $Y = g(X)$. Suponha que existe uma partição $A_0, A_1, \dots, A_k$ de $\mathcal{X}$ tal que $P(X \in A_0) = 0$ e $f_X$ é contínua em todo $A_i$. Além disso, suponha que existem funções $g_1(x), g_2(x), \dots, g_k(x)$ definidas em $A_1, A_2, \dots, A_k$ respectivamente que satisfazem
1) $g(x) = g_i(x)$ para todo $x \in A_i$,
2) $g_i(x)$ é monótona em $A_i$,
3) o conjunto $\mathcal{Y} = \{y| y = g_i(x) \quad \text{para algum} \quad x \in A_i\}$ é o mesmo para  $i = 1, 2, \dots, k$,
4) $g^{-1}_i(y)$ tem derivada contínua em $\mathcal{Y}$, para $i = 1, 2, \dots, k$.
Então
$$f_Y(y) = \sum_{i = 1}^k f_X(g^{-1}_i(y)) |\frac{d}{dy}g^{-1}_i(y)| \mathbb{1}_{y \in \mathcal{Y}}$$
Prova em [[202410060827]].

**Teorema**: Seja $X$ uma variável contínua com $fda$ $F_X(x)$, e defina $Y = F_X(X)$. Assim, $Y \sim Uniforme(0, 1)$.

### 2.3 Momentos e função geradora de momentos
**Definição**: Para cada inteiro $n$, o $n-ésimo$ momento de $X$ ($F_X(x)$), $\mu_n'$, é definido por $$\mu_n' = E[X^n]$$. O $n-ésimo$ momento central de $X$, $\mu_n$, é definido por $$\mu_n = E[(X - \mu)^n]$$

**Definição**: Seja $X$ uma variável aleatória com $fda$ $F_X$. A função geradora de momentos de $X$, denotada por $M_X(t)$, é dada por $$M_X(t) = E[e^{tX}]$$, dado que essa esperança exista para algum $t$ na vizinhança de $0$. Ou seja, que exista $h > 0$ tal que, para todo $t \in (-h, h)$, $E[e^{tX}]$ exista; caso contrário, dizemos que a função geradora de momentos não existe.

**Observação**: Em geral, uma $fgm$ não caracteriza unicamente uma $fda$. Ou seja, pode haver duas variáveis aleatórias distintas que possuem a mesma $fgm$. Dito isso, os próximos dois teoremas nos dão condições suficientes e necessárias para que a caracterização seja única.

**Teorema**: Sejam $F_X(x)$ e $F_Y(y)$ duas $fda$ cujo todos momentos existem. Assim,
1) Se $X$ e $Y$ possuem suportes limitados, então $F_X(u) = F_Y(u)$ para todo $u$ se, e somente se, $E[X^r] = E[Y^r]$ para todo $r = 0, 1, 2, \dots$.
2) Se a função geradora de momentos existe e $M_X(t) = M_Y(t)$ para todo $t$ em alguma vizinhança de $0$, então $F_X(u) = F_Y(u)$ para todo $u$.

**Teorema**: (Convergência de $fgm$) Suponha que $\{X_1, X_2, \dots\}$ é uma sequência de variáveis aleatórias, cada uma com $fgm$ $M_{X_i}(t)$. Além disso, suponha que $$\lim_{i \rightarrow \infty} M_{X_i}(t) = M_X(t) \quad \text{para todo $t$ numa vizinhança de $0$.}$$, onde $M_X(t)$ também é uma $fgm$. Dessa forma, existe uma única $fda$ $F_X(x)$ cujo momentos são determinados por $M_X(t)$ e, para todo $x$ onde $F_X(x)$ é contínua, nós temos $$\lim_{i \rightarrow \infty} F_{X_i}(x) = F(x)$$. Isso quer dizer que convergência, para $|t| < h$, de $fgm's$ para uma $fgm$ implica convergência das $fda's$.

### 2.4 Diferenciação sob uma integral
Sinceramente, eu preciso de uma base mais sólida de cálculo para entender esse capítulo. Dito isso, a conclusão que posso ter agora é de que é necessário verificar algumas coisas antes de podermos passar uma derivada pra dentro da integral. O mesmo vale para passar uma derivada para dentro de um somatório, mas essa é bem mais simples.

### 2.6 Miscelânea
#### 2.6.1 Unicidade da sequência de momentos
Uma distribuição não é necessariamente caracterizada por seus momentos. Dito isso, existe algumas condições que são suficientes para que esse seja o caso. Aqui, o autor nos mostra três dessas condições.

#### 2.6.2 Outras funções geradoras
Além da função geradora de momentos, existem outras funções geradoras. A *função característica* é a mais útil delas, mas requer entendimento de análise complexa. As outras funções geradoras incluem a *função geradora cumulativa* e a*função geradora de momento fatorial*.

A função característica é definida por: $$\phi_X (t) = E[e^{itX}]$$, onde $i$ é o número complexo $\sqrt{(-1)}$. A função característica sempre existe e determina completamente uma distribuição. Ou seja, toda $fda$ possui uma função característica única.

**Teorema**: (Convergência de funções características) Suponha que $X_k$, $k = 1, 2, \dots$ é uma sequência de variáveis aleatórias, cada uma com função característica $\phi_{X_k}(t)$. Além disso, suponha que $$\lim_{k \rightarrow \infty} \phi_{X_k}(t) = \phi_X (t) \quad \text{para todo t numa vizinhança de 0,}$$
onde $\phi_X (t)$ é uma função característica. Então, para todo $x$ onde $F_X(x)$ é contínua, $$\lim_{k \rightarrow \infty} F_{X_k}(x) = F_X(x).$$

## 3 - Famílias de distribuições comuns
### 3.1 Introdução
Uma família de distribuição é indexada por um ou mais parâmetros, o que nos permite variar algumas características da distribuição enquanto mantemos a mesma forma funcional.

### 3.2 Distribuições discretas
**Definição**: (Distribuição discreta) Uma variável aleatória $X$ é dita ter distribuição discreta se o contra-domínio de $X$ é um conjunto contável.

##### Distribuição Uniforme Discreta
Para provar a esperança e a variância dessa distribuição, podemos usar as seguintes identidades: $$\sum_{i = 1}^n i = \cfrac{n(n+1)}{2} \quad \text{para a esperança}$$ e $$\sum_{i = 1}^n i^2 = \cfrac{n (n+1)(2n+1)}{6} \quad \text{para a variância}$$
##### Distribuição Hipergeométrica
A distribuição hipergeométrica pode ser montada da seguinte maneira: imagine que temos uma urna com $N$ bolas, das quais $M$ são vermelhas e $N - M$ são verdes. Vamos retirar dessa urna, sem reposição, $K$ bolas. Queremos saber a probabilidade de que o número de bolas vermelhas nessas $K$ bolas retiradas ser igual a $x$.

Assim, temos $\left( \begin{array}{c} N \\ K \end{array} \right)$ maneiras de retirar essa amostra. Além disso, há $\left( \begin{array}{c} M \\ x \end{array} \right)$ maneiras de que $x$ dessas bolas sejam vermelhas, e por consequência, $\left( \begin{array}{c} N - M\\ K - x\end{array} \right)$ maneiras de preencher o resto da amostra com bolas verdes. Assim, $$P(X = x | N, M, K) = \cfrac{\left( \begin{array}{c} M \\ x \end{array} \right) \left( \begin{array}{c} N - M\\ K - x\end{array} \right)}{\left( \begin{array}{c} N \\ K \end{array} \right)}$$
Lembrando que o entendimento que devemos ter aqui é de que as bolas da mesma cor são diferenciáveis entre si, como se cada uma tivesse uma marcação única.

Para encontrar a esperança da hipergeométrica, podemos usar as identidades $$x\left( \begin{array}{c} M \\ x \end{array} \right) = M\left( \begin{array}{c} M-1 \\ x-1 \end{array} \right)$$ e manipular a equação tal que tenhamos uma nova distribuição hipergeométrica com parâmetros $N-1, M-1, K-1$ somando de $0$ a $\infty$, resultando em 1.

A hipergeométrica pode ser usada em inspeção de qualidade de um lote de bens. Imagine que tenhamos $25$ produtos num lote, nós amostramos $10$ desses produtos, e nenhum deles é defeituoso. Qual a probabilidade desse evento dado que há 6 peças defeituosas no lote? Esse valor é dado por $P(X = 0 | N = 25, M = 6, K = 10) = 0.028$, demostrando que o evento é bastante improvável se há $6$ *ou mais* produtos defeituosos.

##### Distribuição Binomial
**Teorema**: (Teorema Binomial) Para quaisquer $x, y$ inteiros e $n \geq 0$, temos que $$(x + y)^n = \sum_{i = 0}^n \left( \begin{array}{c} n \\ i \end{array} \right) x^i y^{n - i}$$
A prova é a seguinte: $(x + y)^n = (x+y) (x+y) \dots (x+y)$, $n$ vezes. Pra cada um desses termos, podemos escolher $x$ ou $y$. Para $i = 0, 1, \dots, n$, temos $\left( \begin{array}{c} n \\ i \end{array} \right)$ termos em que $x$ aparece $i$ vezes, $x^i$. Isso porque, para $i = 0$, só temos uma maneira fazer a escolha: todas devem ser $y$. Para $i = 1$, temos $\left( \begin{array}{c} n \\ 1 \end{array} \right) = n$ maneiras de escolher, e assim sucessivamente.

Um corolário que segue desse teorema é a seguinte identidade: $$2^n = (1+1)^n =  \sum_{i = 0}^n \left( \begin{array}{c} n \\ i \end{array} \right)$$
Esse teorema nos ajuda a provar que a densidade da distribuição binomial avaliada em seu suporte soma 1.

Dado que $X \sim Bin(n, p)$, podemos calcular a $P(X = x)$ de forma recursiva: basta notar que $P(X = x) = \frac{(n - x + 1)}{x} \frac{p}{1-p} P(X = x - 1)$.

##### Distribuição Poisson
Para provar que a distribuição Poisson soma $1$, e achar a fórmula da esperança e da variância, podemos usar a expansão da série de Taylor: $$e^y = \sum_{i = 0}^\infty \frac{y^i}{i!}$$
Além disso, dado que $Y \sim Poisson(\lambda)$, podemos calcular $P(Y = y)$ de forma recursiva: $P(Y = y) = \frac{\lambda}{y} P(Y = y - 1).$

**Aproximação da binomial pela Poisson**: dada a fórmula recursiva da binomial, e dado que $X \sim Bin(n, p)$, $P(X = x) = \cfrac{(n - x + 1)}{x} \cfrac{p}{1-p} P(X = x - 1)$. Repare que, para $n$ grande e $p$ pequeno, $\cfrac{(n - x + 1)}{x} \cfrac{p}{1-p} P(X = x - 1) = \cfrac{(np -p(x-1)}{x - px} P(X = x - 1) \approx \cfrac{np}{x} P(X = x - 1)$. Para $np = \lambda$, temos a fórmula recursiva da probabilidade de uma Poisson. Assim, para completar a prova por indução, basta mostrar que, dado que $Y \sim Poisson(\lambda)$, $P(X = 0) = P(Y = 0)$. Logo, $P(X = 0) = (1 - p)^n = (1 - \frac{np}{n})^n = (1 - \frac{\lambda}{n})$. Sabemos que $\lim_{n \rightarrow \infty} (1 - \frac{\lambda}{n}) = e^{-\lambda} = P(Y = 0)$.

##### Distribuição binomial negativa
A distribuição binomial negativa nos dá a probabilidade de que, em experimentos de Bernoulli independentes, são necessários exatamente $x$ tentativas para se obter $r$ sucessos. Assim, se $X \sim NegBin(r, p)$, então $$P(X = x |r, p) = \left( \begin{array}{c} x-1 \\ r-1 \end{array} \right) p^r (1-p)^{n-r}$$. A fórmula segue direto da binomial: para que o $r-ésimo$ sucesso venha na $x-ésima$ tentativa, precisamos que nas $x-1$ tentativas anteriores, tenhamos $r-1$ sucessos em qualquer ordem, ficando $\left( \begin{array}{c} x-1 \\ r-1 \end{array} \right) p^{r-1} (1-p)^{n-r}$. Acontecido isso, basta que o próximo experimento seja sucesso, gerando a fórmula acima.

A distribuição binomial negativa também pode ser definida como o número de fracassos antes de se obter $r$ sucessos. Assim, tomando $Y = X - r$, temos que $Y$ representa exatamente isso. A $fmp$ então é dada por $P(Y = y | r, p)  = \left( \begin{array}{c} y + r -1 \\ y \end{array} \right) p^r (1-p)^{n-r}$. Essa $fmp$ será a padrão utilizada pelo livro.

A binomial negativa tem esse nome por causa da seguinte identidade: $\left( \begin{array}{c} y + r -1 \\ y \end{array} \right) = (-1)^y \left( \begin{array}{c} -r \\ y \end{array} \right)$, que quando substituída na fórmula original, gera: $P(Y = y | r, p)  = (-1)^y \left( \begin{array}{c} -r\\ y \end{array} \right) p^r (1-p)^{n-r}$, o que realmente lembra uma distribuição binomial.

A esperança e a variância dessa distribuição podem ser encontradas de forma semelhe as da hipergeométrica: se inicia com a fórmula da esperança, e se manipula a equação até que tenhamos a $fmp$ de uma $BinNeg(r +1, p)$ somando sobre todo o suporte, gerando 1. Dito isso, não é simples de se provar que a $fmp$ da binomial negativa soma 1 em seu suporte.

Outros dois fatos interessantes é que a variância da binomial negativa é uma função quadrática da sua média, e que quando $r \rightarrow \infty$ e $p \rightarrow 1$, $BinNeg(r, p) \rightarrow Poisson(\lambda)$. Podemos verificar esse fato pela convergência das funções geradoras de momentos.

A binomial negativa também pode ser utilizada para amostrar populações biológicas, uma técnica conhecida como *amostragem binomial inversa*. Dado que uma característica está presente numa proporção $p$ de uma população, podemos calcular a probabilidade de precisarmos de mais de $N$ amostras para encontrar $r$ indivíduos com essa característica. 

Esse exemplo nos mostra como a binomial negativa, assim como a Poisson,  pode ser usada para modelar fenômenos onde estamos esperando por uma ocorrência. No caso da binomial negativa, estamos esperando por um número de sucessos especificado.

##### Distribuição geométrica
A distribuição geométrica também é uma distribuição na qual estamos esperando por uma ocorrência; no caso, o primeiro sucesso. Ela é um caso específico da distribuição binomial negativa ($r = 1$).

Além disso, ela é a única distribuição discreta que não possui memória ($P(X > s | X > t ) = P(X > s - t)$).

A distribuição geométrica pode ser utilizada para modelar tempo de vida de algum componente. Para isso, precisamos saber a probabilidade de o componente falhar numa unidade discreta de tempo, por exemplo, dia, e é necessário que a probabilidade de falha se mantenha constante ao longo do tempo, ou seja, ela não pode aumentar com a passagem do tempo, que é o caso mais comum na prática.

### 3.2 Distribuições contínuas
##### Distribuição uniforme
Sem maiores comentários.

##### Distribuição Gama
A distribuição gama pode ser derivada utilizando as técnicas discutidas [[#1.6 Funções densidade e massa]]: primeiro, escolhemos uma função e um suporte tal que função escolhida tenha valores positivos nesse suporte, e sua integral nesses valores seja finita; depois disso, basta dividir a função escolhida pelo valor da integral, e teremos uma $fdp$. 

Assim, tomemos a função gama e o intervalo $(0, \infty)$.  Ela é definida por $\Gamma(\alpha) = \int_0^\infty t^{\alpha - 1} e^{-t}dt$ para $\alpha > 0$. Provamos que ela é finita ([[202410220703.excalidraw]]). 

A função gama satisfaz as seguintes propriedades: $\Gamma(\alpha + 1) = \alpha \Gamma(\alpha) \quad \alpha > 0$  e $\Gamma(1) = 1$, nos permitindo afirmar que $\Gamma(n) = (n - 1)!$ para qualquer $n$ inteiro. ([[202410230603.excalidraw]]). 

Como o integrando da função gama é positivo, segue que $$f(t) = \cfrac{t^{\alpha - 1} e^t dt}{\Gamma(\alpha)}, \quad 0 < t < \infty$$ é uma $fdp$. Repare que a integral dessa função no suporte é $1$.

Entretanto, essa ainda não é a família de distribuição gama, pois essa família possui dois parâmetros. Dessa forma, podemos obter essa família definindo $X = \beta T$, onde $\beta > 0$ e $T$ é uma variável aleatória cuja $fdp$ é dada acima. Assim, teremos que ([[202410230622.excalidraw]]) $$ f_X(x | \alpha, \beta) = \cfrac{x^{\alpha - 1} e^{-\frac{x}{\beta}}}{\Gamma(\alpha) \beta^\alpha} \mathbb{1}_{(0, \infty)}$$
A esperança e a variância da gama podem ser calculados de forma semelhante ao que foi utilizado na binomial: tentamos encontrar um kernel de uma função gama na integral, nos poupando de termos que realizar os cálculos.

A distribuição gama possui algumas relações com outras distribuições:

**Gama e Poisson**: Para $i \in \mathbb{N}$, seja $X_i \sim Gama(i, \beta)$ e $Y \sim Poisson(\frac{x}{\beta})$. Dessa forma ([[202410240801.excalidraw]]), $$P(X_i < x) = P(Y \geq i)$$
**Gama e Qui-quadrado**: Para $p \in \mathbb{N}$, seja $X \sim Gama(\frac{p}{2}, 2)$. Assim, $$f_X(x | p) = \cfrac{x^{\frac{p}{2} - 1} e^{\frac{-x}{2}}}{\Gamma(\frac{p}{2}) 2^{\frac{p}{2}}} \mathbb{1}_{(0, \infty)}(x)$$, que é a densidade de uma variável aleatória qui-quadrado com $p$ graus de liberdade. A esperança e a variância da qui-quadrado podem ser obtidas a partir da esperança e da variância da gama.

**Gama e Exponencial**: Seja $X \sim Gama(1, \beta)$. Assim, $$f_X(x | \beta) = \frac{e^{\frac{-x}{\beta}}}{\beta}\mathbb{1}_{(0, \infty)}(x).$$
Que é a densidade de uma variável aleatória exponencial com parâmetro *escala* $\beta$. O parâmetro escala é o inverso do parâmetro taxa, que é o que estou acostumado com.

**Gama, Exponencial e Weibull**: Seja $X \sim Exp(\beta)$ e $Y \sim X^{\cfrac{1}{\gamma}}$. Assim ([[202410240853.excalidraw]]), $$f_Y(y) = \frac{\gamma}{\beta} y^{\gamma - 1}e^{\frac{y^\gamma}{\beta}} \mathbb{1}_{(0, \infty)}$$
, onde $\beta > 0$ e $\gamma > 0$. A distribuição Weibull é muito útil para modelar funções de risco de tempo de vida.

##### Distribuição Normal
Para calcular a esperança de uma normal qualquer, podemos calcular a esperança da normal padrão, que é fácil de ser calculada, depois utilizar o fato de que $E[X] = E[\mu + Z \sigma] = \mu$. O cálculo da variância segue o mesmo padrão, mas é necessário utilizar integração por partes ([[202410250615.excalidraw]]).

Para provar que a $fdp$ da normal padrão integra $1$ é uma conta bem complicadinha. Eu vou pular ela por hora, mas vou dizer que envolve elevar a integral ao quadrado e usar coordenadas polares.











# Reference
[[Statistical Inference]]

